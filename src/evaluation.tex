\section{Evaluation Plan}\label{evaluation}
    In order to evaluate our approach, we need to determine if we have collected enough data that we can generalize our result to a greater scope. The first goal of our project is to ensure that we have reliable data that are significant enough for our research. By having a metric that keeps track of the packet capture rate, we can immediately tell if there will be problems with the data we collected when the capture rate drops.

    The earlier goal is to determine how well the trends of QoE~data match with QoS~data. The way we determine this would be general statistical analysis, which analyzes the relationships, relatabilities, and confidence intervals. By generating plots and graphs, we should be able to view the result very clearly. Moreover, if Machine Learning models are implemented, we can always use metrics, like accuracy, precision, and recall, to evaluate the models. Furthermore, we can always capture packets and generate new training and test sets on our test router, for further training and testing. 

    The later goal is to make sure that our machine learning model mapping from encrypted packet payloads to QoE does not overfit or underfit the data we use to train it. It should be applicable to real-world networks. It is also very easy to evaluate: by running it on a private router, we would be able to manipulate the QoS like uplink and downlink bitrates by ourselves and see the matches and differences between the calculated QoE and the real QoE. 

